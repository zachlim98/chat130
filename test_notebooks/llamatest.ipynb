{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index\n",
    "! pip install azure-search-documents==11.4.0b8 --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import keys\n",
    "\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.schema import MetadataMode\n",
    "\n",
    "from llama_index.embeddings import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    engine=\"raidGPT\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.0,\n",
    "    api_base=\"https://raid-ses-openai.openai.azure.com/\",\n",
    "    api_key=keys.gpt_key,\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "emb_llm = OpenAIEmbedding(\n",
    "    engine=\"swiftfaq-ada002\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    temperature=0.0,\n",
    "    api_base=\"https://raid-ses-openai.openai.azure.com/\",\n",
    "    api_key=keys.gpt_key,\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2023-05-15\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('../data/124').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "import keys\n",
    "\n",
    "from llama_index.vector_stores.cogsearch import (\n",
    "    IndexManagement,\n",
    "    CognitiveSearchVectorStore,\n",
    "    MetadataIndexFieldType\n",
    ")\n",
    "\n",
    "from llama_index import (\n",
    "    LangchainEmbedding,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    ServiceContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "\n",
    "service_endpoint = \"https://aimlexplorationsearch.search.windows.net\"\n",
    "index_name = \"rsaf-cognitive-search\"\n",
    "key = keys.cognitive_key\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating own nodes from azure output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import CustomQueryEngine\n",
    "from llama_index.retrievers import BaseRetriever\n",
    "from llama_index.response_synthesizers import get_response_synthesizer, BaseSynthesizer\n",
    "from llama_index.schema import Node, NodeWithScore\n",
    "from llama_index import QueryBundle\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A\n",
      " fen\n",
      "est\n",
      "ron\n",
      " is\n",
      " a\n",
      " type\n",
      " of\n",
      " tail\n",
      " rotor\n",
      " design\n",
      " used\n",
      " in\n",
      " helicopters\n",
      ".\n",
      " It\n",
      " is\n",
      " characterized\n",
      " by\n",
      " its\n",
      " aer\n",
      "odynam\n",
      "ically\n",
      " efficient\n",
      " design\n",
      " that\n",
      " produces\n",
      " smaller\n",
      " tip\n",
      " v\n",
      "ort\n",
      "ices\n",
      " on\n",
      " the\n",
      " ends\n",
      " of\n",
      " the\n",
      " rotor\n",
      " blades\n",
      ",\n",
      " reducing\n",
      " drag\n",
      " and\n",
      " maximizing\n",
      " thrust\n",
      " produced\n",
      ".\n",
      " The\n",
      " fen\n",
      "est\n",
      "ron\n",
      " has\n",
      " seven\n",
      " st\n",
      "ator\n",
      " van\n",
      "es\n",
      " that\n",
      " assist\n",
      " in\n",
      " straight\n",
      "ening\n",
      " and\n",
      " guiding\n",
      " the\n",
      " air\n",
      " flow\n",
      " for\n",
      " the\n",
      " optimum\n",
      " Angle\n",
      " of\n",
      " Attack\n",
      " (\n",
      "AO\n",
      "A\n",
      ")\n",
      " on\n",
      " the\n",
      " rotor\n",
      " blades\n",
      ".\n",
      " The\n",
      " dynamic\n",
      " section\n",
      " has\n",
      " \n",
      "8\n",
      " asymmetric\n",
      "ally\n",
      " spaced\n",
      " rotor\n",
      " blades\n",
      " that\n",
      " rotate\n",
      " clockwise\n",
      " in\n",
      " a\n",
      " '\n",
      "Union\n",
      " Jack\n",
      "'\n",
      " arrangement\n",
      " to\n",
      " optimize\n",
      " performance\n",
      " and\n",
      " reduce\n",
      " noise\n",
      ".\n",
      " The\n",
      " fen\n",
      "est\n",
      "ron\n",
      " is\n",
      " controlled\n",
      " in\n",
      " the\n",
      " same\n",
      " way\n",
      " as\n",
      " a\n",
      " conventional\n",
      " tail\n",
      " rotor\n",
      " system\n",
      ",\n",
      " with\n",
      " the\n",
      " pilot\n",
      "'s\n",
      " pedal\n",
      " inputs\n",
      " changing\n",
      " the\n",
      " pitch\n",
      " of\n",
      " all\n",
      " the\n",
      " tail\n",
      " rotor\n",
      " blades\n",
      " through\n",
      " a\n",
      " mechanical\n",
      " linkage\n",
      " to\n",
      " the\n",
      " tail\n",
      " gearbox\n",
      ".\n",
      " The\n",
      " fen\n",
      "est\n",
      "ron\n",
      " design\n",
      " also\n",
      " significantly\n",
      " reduces\n",
      " noise\n",
      " compared\n",
      " to\n",
      " a\n",
      " traditional\n",
      " tail\n",
      " rotor\n",
      ",\n",
      " and\n",
      " its\n",
      " sh\n",
      "rou\n",
      "ded\n",
      " design\n",
      " allows\n",
      " for\n",
      " a\n",
      " safer\n",
      " working\n",
      " area\n",
      " for\n",
      " crews\n",
      " with\n",
      " rot\n",
      "ors\n",
      " turning\n",
      " and\n",
      " helps\n",
      " minimize\n",
      " tail\n",
      " rotor\n",
      " strikes\n",
      " when\n",
      " landing\n",
      " at\n",
      " un\n",
      "prepared\n",
      " landing\n",
      " sites\n",
      ".\n",
      "\n",
      "\n",
      "The\n",
      " information\n",
      " was\n",
      " sourced\n",
      " from\n",
      " the\n",
      " following\n",
      " documents\n",
      ":\n",
      "\n",
      "\n",
      "Filename\n",
      ":\n",
      " E\n",
      "EM\n",
      " FINAL\n",
      " ca\n",
      "a\n",
      "201\n",
      "221\n",
      "-\n",
      "1\n",
      "-\n",
      "50\n",
      ".pdf\n",
      "\n",
      "\n",
      "Page\n",
      ":\n",
      " \n",
      "14\n",
      "\n",
      "\n",
      "\n",
      "Filename\n",
      ":\n",
      " E\n",
      "EM\n",
      " FINAL\n",
      " ca\n",
      "a\n",
      "201\n",
      "221\n",
      "-\n",
      "1\n",
      "-\n",
      "50\n",
      ".pdf\n",
      "\n",
      "\n",
      "Page\n",
      ":\n",
      " \n",
      "15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.chat_engine import CondenseQuestionChatEngine, ContextChatEngine\n",
    "from azure.search.documents.models import Vector\n",
    "\n",
    "class AzureRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Custom retriever that searches from Azure Search Index.\n",
    "    Ability to enable hybrid (keyword + vector), keyword, or just vector mode\n",
    "    For examples of valid filtering, refer to https://learn.microsoft.com/en-us/azure/search/search-query-odata-filter\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        search_client : SearchClient,\n",
    "        embed_model, \n",
    "        filter : str,\n",
    "        mode = \"hybrid\"\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._search_client = search_client\n",
    "        self._embed_model = embed_model\n",
    "        self._filter = filter\n",
    "        self._mode = mode\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        nodes = []\n",
    "        \n",
    "        if self._mode == \"vector\":\n",
    "            vector = Vector(value=self._embed_model.get_text_embedding(query_bundle.query_str), k=6, fields=\"embedding\")\n",
    "            results = self._search_client.search(search_text=None, vectors=[vector], filter=self._filter, top=3)\n",
    "            \n",
    "        elif self._mode == \"keyword\":\n",
    "            results = self._search_client.search(search_text=query_bundle, filter=self._filter, top=6)\n",
    "            \n",
    "        else:\n",
    "            vector = Vector(value=self._embed_model.get_text_embedding(query_bundle.query_str), k=6, fields=\"embedding\")\n",
    "            results = self._search_client.search(search_text=query_bundle, vectors=[vector], filter=self._filter, top=3)\n",
    "        \n",
    "        # citations management\n",
    "        # possible for rights management (post filtering)\n",
    "        for i in results:\n",
    "            text_body = \"Filename: \" + i[\"filename\"] + \"\\n\" + \"Page Number: \" + str(i[\"page\"]) + \"\\n\" + \"Content: \" + i[\"content\"] + \"\\n-----------------------\"\n",
    "            nodes.append(NodeWithScore(node=Node(text=text_body), score=i['@search.score']))\n",
    "\n",
    "        return nodes\n",
    " \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=\"rsaf-cognitive-search\", credential=credential)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=emb_llm)\n",
    "    \n",
    "chat_engine = ContextChatEngine.from_defaults(retriever=AzureRetriever(search_client=search_client, embed_model=emb_llm, filter=\"\"), verbose=True, service_context=service_context)\n",
    "\n",
    "response = chat_engine.stream_chat(\"Describe what a fenestron is. Provide the filename and page number of the two main sources that was used to generate the information. The source will be in the format:\\n Filename: \\n Page: \")\n",
    "\n",
    "for i in response.response_gen:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 15]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_page_numbers(text):\n",
    "    pattern = r'Page:\\s*(\\d+)'\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "    return [int(match) for match in matches]\n",
    "\n",
    "# Test the function\n",
    "print(find_page_numbers(response.response)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API friendly version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This creates a new llamaindex compatible Azure Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_index = SearchIndexClient(endpoint=service_endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_azure_index(index_client, index_name : str, metadata_fields : dict, llm, emb_llm, filepath) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    Spins up an azure cognitive search index.\n",
    "    Will delete any index named as such so BE CAREFUL\n",
    "    \"\"\"\n",
    "    \n",
    "    vector_store = CognitiveSearchVectorStore(\n",
    "        search_or_index_client=index_client,\n",
    "        index_name=index_name,\n",
    "        filterable_metadata_field_keys=metadata_fields,\n",
    "        index_management=IndexManagement.CREATE_IF_NOT_EXISTS,\n",
    "        id_field_key=\"id\",\n",
    "        chunk_field_key=\"content\",\n",
    "        embedding_field_key=\"embedding\",\n",
    "        metadata_string_field_key=\"li_jsonMetadata\",\n",
    "        doc_id_field_key=\"li_doc_id\",\n",
    "    )\n",
    "    \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    service_context = ServiceContext.from_defaults(llm=llm, embed_model=emb_llm)\n",
    "    \n",
    "    documents = SimpleDirectoryReader(filepath).load_data()\n",
    "    \n",
    "    ####################################\n",
    "    # Chunking/Form Intelligence here  #\n",
    "    ####################################\n",
    "    \n",
    "    \n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, storage_context=storage_context, service_context=service_context\n",
    ")\n",
    "    \n",
    "    return \"{}\".format(index_name) + \" created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_azure_index(index_client=client_index, index_name=\"chat-demo\", metadata_fields={\"total_pages\" : (\"total_pages\", MetadataIndexFieldType.INT32),\n",
    "                                                                                       \"page\" : (\"page\", MetadataIndexFieldType.INT32),\n",
    "                                                                                       \"filename\" : (\"filename\", MetadataIndexFieldType.STRING)}, \n",
    "                   llm = llm, emb_llm=emb_llm, filepath=\"../data/124\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"page_number\": 23,\n",
    "            \"filename\": \"Friendship\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"page_number\": 24,\n",
    "            \"filename\": \"Mafia\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Inception\",\n",
    "        metadata={\n",
    "            \"page_number\": 25,\n",
    "            \"filename\": \"Friendship\",\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "vector_store = CognitiveSearchVectorStore(\n",
    "    search_or_index_client=client_index,\n",
    "    index_name=\"nodes-test\",\n",
    "    filterable_metadata_field_keys={\"filename\" : \"filename\"},\n",
    "    index_management=IndexManagement.CREATE_IF_NOT_EXISTS,\n",
    "    id_field_key=\"id\",\n",
    "    chunk_field_key=\"content\",\n",
    "    embedding_field_key=\"embedding\",\n",
    "    metadata_string_field_key=\"li_jsonMetadata\",\n",
    "    doc_id_field_key=\"li_doc_id\",\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=emb_llm)\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "        nodes, storage_context=storage_context, service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing custom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"quickstart\"\n",
    "\n",
    "metadata_fields = {\n",
    "    \"page_label\": \"page_label\",\n",
    "    \"theme\": \"theme\",\n",
    "    \"director\": \"director\",\n",
    "}\n",
    "\n",
    "client_index = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "vector_store = CognitiveSearchVectorStore(\n",
    "    search_or_index_client=client_index,\n",
    "    index_name=index_name,\n",
    "    filterable_metadata_field_keys=metadata_fields,\n",
    "    index_management=IndexManagement.CREATE_IF_NOT_EXISTS,\n",
    "    id_field_key=\"id\",\n",
    "    chunk_field_key=\"content\",\n",
    "    embedding_field_key=\"embedding\",\n",
    "    metadata_string_field_key=\"li_jsonMetadata\",\n",
    "    doc_id_field_key=\"li_doc_id\",\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=emb_llm)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "        documents, storage_context=storage_context, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This creates a custom retriever with a chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.chat_engine import CondenseQuestionChatEngine, ContextChatEngine\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both semantic search and hybrid search.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        search_client : SearchClient,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._search_client = search_client\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        nodes = []\n",
    "        # filtering\n",
    "        results = self._search_client.search(search_text=query_bundle, top=3)\n",
    "        # citations management\n",
    "        # possible for rights management (post filtering)\n",
    "        for i in results:\n",
    "            nodes.append(NodeWithScore(node=Node(text=i[\"content\"]), score=i['@search.score']))\n",
    "\n",
    "        return nodes\n",
    " \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=\"chat-demo\", credential=credential)\n",
    "    \n",
    "chat_engine = ContextChatEngine.from_defaults(retriever=CustomRetriever(search_client=search_client), verbose=True, service_context=service_context)\n",
    "\n",
    "chat_engine.chat(\"What are advanced transitions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This allows you to query that index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom class that calls on search client\n",
    "class AzureQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"Azure Custom Query.\"\"\"\n",
    "\n",
    "    search_client : SearchClient\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    \n",
    "    def custom_query(self, query_str: str):\n",
    "        \n",
    "        nodes = []\n",
    "        # filtering\n",
    "        results = self.search_client.search(search_text=query_str, top=3)\n",
    "        # citations management\n",
    "        # possible for rights management (post filtering)\n",
    "        for i in results:\n",
    "            nodes.append(NodeWithScore(node=Node(text=i[\"content\"]), score=i['@search.score']))\n",
    "\n",
    "        response_obj = self.response_synthesizer.synthesize(query_str, nodes)\n",
    "        return response_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_azure_query_engine(service_endpoint, llm, emb_llm):\n",
    "    \n",
    "    service_context = ServiceContext.from_defaults(llm=llm, embed_model=emb_llm)\n",
    "\n",
    "    search_client = SearchClient(endpoint=service_endpoint, index_name=\"llamaindex-demo\", credential=credential)\n",
    "    \n",
    "    synthesizer = get_response_synthesizer(response_mode=\"compact\", service_context=service_context)\n",
    "    query_engine = AzureQueryEngine(search_client=search_client, response_synthesizer=synthesizer)\n",
    "\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
